{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Analyzing Tweets_PySpark_Batch Analytics.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "sScqs9LISYBx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y7qPzWe5et5l",
        "colab_type": "text"
      },
      "source": [
        "### Install spark dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S3PWSgrib82k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TaFsoCRnexGa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget https://downloads.apache.org/spark/spark-2.4.6/spark-2.4.6-bin-hadoop2.6.tgz"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JhxFAJCMe49f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!tar xf spark-2.4.6-bin-hadoop2.6.tgz"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sAyiyWkpfCTt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install -q findspark\n",
        "!pip install pyspark"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nXJk6jID3fCS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget http://apachemirror.wuchna.com/hadoop/common/stable/hadoop-3.2.1.tar.gz\n",
        "!tar xf hadoop-3.2.1.tar.gz"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dzhkBfKDfPxE",
        "colab_type": "text"
      },
      "source": [
        "### Setup required environment variables"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FWgbujJ8fJ0a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-2.4.6-bin-hadoop2.6\"\n",
        "os.environ['HADOOP_HOME'] = '/content/hadoop-3.2.1'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SJ8ATKXGfgZz",
        "colab_type": "text"
      },
      "source": [
        "### Import required libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ay2sy0_mfVJL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pyspark import SparkContext\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.ml.classification import RandomForestClassifier\n",
        "from pyspark.ml.feature import IndexToString, StringIndexer, VectorIndexer, VectorAssembler\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "\n",
        "from pyspark.sql.functions import isnan, when, count, col"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LfVN8LK5lDMN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pyspark.sql.functions import UserDefinedFunction\n",
        "from pyspark.sql.types import StringType\n",
        "from pyspark.sql.types import IntegerType\n",
        "from pyspark.sql.functions import *\n",
        "\n",
        "import json"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J4xFiGyqpnOu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gu1Y1TEufs1_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Connect to the Spark server\n",
        "SparkContext.setSystemProperty('spark.executor.memory', '4g')\n",
        "\n",
        "spark = SparkSession.builder.appName(\"Covid-Tweet\").master(\"local[*]\").getOrCreate()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ScoJ2yeJgqwv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%time\n",
        "!mkdir SPARK-2020-01\n",
        "!cp drive/\"My Drive\"/\"SPARK+AI Hackathon 2020\"/SPARK-2020-05/*.*  SPARK-2020-01/\n",
        "\n",
        "!cp drive/\"My Drive\"/\"SPARK+AI Hackathon 2020\"/SPARK-2020-01/*.*  SPARK-2020-01/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TEq8_B4Bg6Kn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# filename05 = os.listdir('SPARK-2020-05')\n",
        "# filename05 = [ 'SPARK-2020-05/' + f for f in filename05]\n",
        "# print(len(filename05))\n",
        "\n",
        "# filename01 = os.listdir('SPARK-2020-01')\n",
        "# filename01 = [ 'SPARK-2020-01/' + f for f in filename01]\n",
        "# print(len(filename01))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EttInxlcf4sy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%time\n",
        "# Create data frame. spark.read.json >>> can also read from a directory \n",
        "json_file_path = 'SPARK-2020-01'\n",
        "df = spark.read.json(json_file_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TaQlIHQ6jFRZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# The inferred schema can be visualized using the printSchema() method\n",
        "#df.printSchema()\n",
        "\n",
        "#df.show(5)\n",
        "\n",
        "#df.dtypes\n",
        "\n",
        "#print((df.count(), len(df.columns)))\n",
        "\n",
        "# Creates a temporary view using the DataFrame\n",
        "#df.createOrReplaceTempView(\"tweets\")\n",
        "\n",
        "# SQL statements can be run by using the sql methods provided by spark\n",
        "#tweetsDF = spark.sql(\"SELECT * FROM tweets\")\n",
        "#tweetsDF.show(10)\n",
        "\n",
        "#df.describe('favorite_count').show()\n",
        "\n",
        "# The following code block gives a null value\n",
        "\n",
        "# from pyspark.sql import functions as F\n",
        "\n",
        "# df2 = spark.createDataFrame([('Tue May 05 16:14:52 +0000 2020',)], ['t'])\n",
        "# df2 = df2.withColumn('new_date', df2.t.substr(1,19))\n",
        "# df2 = df2.withColumn('dt', F.to_date(df2.new_date, 'EEE MMM dd HH:MM:SS'))\n",
        "# print(df2.show())\n",
        "\n",
        "# This gives a OOM error \n",
        "# result = df.select('*').toPandas()\n",
        "\n",
        "## Instead add limit(n)\n",
        "# result = df.select('*').limit(100).toPandas()\n",
        "\n",
        "# df = df.withColumn('Day', df.created_at.substr(9,10))\n",
        "# df = df.withColumn('Hour', df.created_at.substr(12,13))\n",
        "\n",
        "# df.show(10, truncate=False)\n",
        "\n",
        "# df.select('entities', 'full_text').show(100,truncate=False)\n",
        "\n",
        "# from pyspark.sql.functions import flatten\n",
        "# df.select(df.full_text,flatten(df.entities)).show(100, truncate=False)\n",
        "\n",
        "# df.select(\"full_text\" , \"user\").show(10, truncate=False)\n",
        "\n",
        "# # Creates a temporary view using the DataFrame\n",
        "# df.createOrReplaceTempView(\"tweets\")\n",
        "\n",
        "# # SQL statements can be run by using the sql methods provided by spark\n",
        "# tweetsDF = spark.sql(\"SELECT * FROM tweets\").limit(100)\n",
        "# #tweetsDF.show(10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k1QftOQLe36a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.show(5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3T28t9xdjOWH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.count()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7IqrXdzPlUaV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def user(text):\n",
        "  return text['screen_name']\n",
        "\n",
        "def hashtag(text):\n",
        "  return [h[1] for h in text[0]]\n",
        "  #return text[0]\n",
        "\n",
        "def user_mention(text):\n",
        "  return [h[-1] for h in text[-1]]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4BD5lSjjm4h7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pyspark.sql.types import ArrayType \n",
        "\n",
        "# Define your function\n",
        "getSN = UserDefinedFunction(lambda x: user(x), StringType())\n",
        "getHash = UserDefinedFunction(lambda x: hashtag(x), ArrayType(StringType()))\n",
        "getUM = UserDefinedFunction(lambda x: user_mention(x), ArrayType(StringType()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3hF50OqVDOkf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "user = df.withColumn('user', getSN(col('user'))) #.show(5)  #<<- This works "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KxX1faxpDTFO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "user = user.withColumn('entities', explode(array('entities'))) #.show(5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PHanrXWhHgpK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "user = user.withColumn('hashtags', getHash('entities')) #.show(50)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rO8hGNmbMIRW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "user = user.withColumn('user_mention', getUM('entities'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RK9-mgNTBDEH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "user.select('user', 'hashtags', 'user_mention', 'full_text').show(50)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7X5xY1L4OmKd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "query = user.select('user', 'hashtags', 'user_mention', 'full_text')\n",
        "query.dtypes # csv can't save a csv file with columns in array<strin> format"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "28caLQogRozP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sparse_format_udf = udf(lambda x: ','.join([str(elem) for elem in x], StringType()))\n",
        "\n",
        "query = query.withColumn('hashtags', sparse_format_udf(col('hashtags')))\n",
        "query = query.withColumn('user_mention', sparse_format_udf(col('user_mention')))\n",
        "query.dtypes"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x3W5C79UPS5e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "type(query)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6R3Wh6pWK-aG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "The following statements are causing an error \n",
        ">>>\n",
        "raise Py4JError(\n",
        "\n",
        "An error occurred while calling o278.collectToPython\n",
        "\n",
        "TypeError: join() takes exactly one argument (2 given)\n",
        "'''\n",
        "# query.limit(1000).toPandas().to_excel('Output.xlsx')\n",
        "\n",
        "# # Save file local folder, delimiter by default is ,\n",
        "# query.coalesce(1).write.format('csv').option('header',\"True\").mode('overwrite').option('sep',',').save('output')\n",
        "\n",
        "# query.write.format(\"parquet\").save(\"jan2020.parquet\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ybXcmEHLXKp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}